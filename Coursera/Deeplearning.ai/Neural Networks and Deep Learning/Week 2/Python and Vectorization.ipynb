{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using vectorization in Python\n",
    "\n",
    "## 1. Vectorized vs. For Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "HOW_LONG_TO_RUN = 100\n",
    "\n",
    "a = np.random.rand(1000000)\n",
    "b = np.random.rand(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorized(a, b, nb_times):\n",
    "    m = []\n",
    "    for i in xrange(nb_times):\n",
    "        tic = time.time()\n",
    "        c = np.dot(a, b)\n",
    "        toc = time.time()\n",
    "        #print(\"Vectorized version: \" + str(1000*(toc - tic)) + \" ms\")\n",
    "        m.append(1000*(toc - tic))\n",
    "\n",
    "    mean_m = (np.array(m).sum())/float(nb_times)\n",
    "    return mean_m, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of 100 runnings as vectorized version: 0.910415649414 ms\n",
      "Value: 250490.600103\n"
     ]
    }
   ],
   "source": [
    "mean_m, c = vectorized(a, b, HOW_LONG_TO_RUN)\n",
    "print(\"Mean of \"+ str(HOW_LONG_TO_RUN) +\" runnings as vectorized version: \"+ str(mean_m) +\" ms\")\n",
    "print(\"Value: \"+ str(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def for_loop_zip(a, b, nb_times):\n",
    "    m = []\n",
    "    c = 0\n",
    "    for i in xrange(nb_times):\n",
    "        tic = time.time()\n",
    "        for a_j, b_j in zip(a, b):\n",
    "            c += a_j * b_j\n",
    "        toc = time.time()\n",
    "        #print(\"Zip version: \" + str(1000*(toc - tic)) + \" ms\")\n",
    "        m.append(1000*(toc - tic))\n",
    "\n",
    "    mean_m = (np.array(m).sum())/float(nb_times)\n",
    "    return mean_m, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of 100 runnings as for loop version: 406.943519115 ms\n",
      "Value: 25049060.0103\n"
     ]
    }
   ],
   "source": [
    "mean_m, c = for_loop_zip(a, b, HOW_LONG_TO_RUN)\n",
    "print(\"Mean of \"+ str(HOW_LONG_TO_RUN) +\" runnings as for loop version: \"+ str(mean_m) +\" ms\")\n",
    "print(\"Value: \"+ str(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def for_loop(a, b, nb_times):\n",
    "    m = []\n",
    "    c = 0\n",
    "    for i in xrange(nb_times):\n",
    "        tic = time.time()\n",
    "        for j in range(len(a)):\n",
    "                c += a[j] * b[j]\n",
    "        toc = time.time()\n",
    "        #print(\"Loop version: \" + str(1000*(toc - tic)) + \" ms\")\n",
    "        m.append(1000*(toc - tic))\n",
    "\n",
    "    mean_m = (np.array(m).sum())/float(nb_times)\n",
    "    return mean_m, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of 100 runnings as for loop version: 349.924705029 ms\n",
      "Value: 25049060.0103\n"
     ]
    }
   ],
   "source": [
    "mean_m, c = for_loop(a, b, HOW_LONG_TO_RUN)\n",
    "print(\"Mean of \"+ str(HOW_LONG_TO_RUN) +\" runnings as for loop version: \"+ str(mean_m) +\" ms\")\n",
    "print(\"Value: \"+ str(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2. Logistic Regression with vectors\n",
    "\n",
    "\n",
    "### Calculating for $m$ examples and $n = 2$ features <font color='red'>without</font> vectorization\n",
    "\n",
    "$\n",
    "J = 0; dw_1 = 0; dw_2 = 0; db = 0 \\\\\n",
    "\\\\\n",
    "\\text{For}\\ \\ i=1\\ \\ \\text{to}\\ \\ m \\\\\n",
    "\\hspace{15pt}z^{(i)} = w^Tx^{(i)} + b \\\\ \n",
    "\\hspace{15pt}a^{(i)} = \\sigma(z^{(i)}) \\\\\n",
    "\\hspace{15pt}J\\ += - [y^{(i)}\\ log(a^{(i)}) + (1 - y^{(i)})\\ log(1 - a^{(i)})] \\\\\n",
    "\\hspace{15pt}dz^{(i)} = a^{(i)} - y^{(i)} \\\\\n",
    "\\hspace{15pt}dw_1 += x_1^{(i)}dz^{(i)} \\\\\n",
    "\\hspace{15pt}dw_2 += x_2^{(i)}dz^{(i)} \\\\\n",
    "\\hspace{15pt}db += dz^{(i)} \\\\\n",
    "\\hspace{15pt}J\\ /=\\ m \\\\\n",
    "\\hspace{15pt}dw_1\\ /=\\ m \\\\\n",
    "\\hspace{15pt}dw_2\\ /=\\ m \\\\\n",
    "\\hspace{15pt}db\\ /=\\ m \\\\\n",
    "\\text{Fim for}\n",
    "$\n",
    "\n",
    "### Updating weights\n",
    "\n",
    "$\n",
    "w_1\\ := w_1 - \\alpha dw_1 \\\\\n",
    "w_2\\ := w_2 - \\alpha dw_2 \\\\\n",
    "b\\ := b - \\alpha db \\\\\n",
    "$\n",
    "\n",
    "### Calculating for $m$ examples and $n = 2$ features <font color='red'>with</font> vectorization\n",
    "\n",
    "$\n",
    "J = 0; dw = np.zeros((n_x, 1)); db = 0; \\\\\n",
    "\\\\\n",
    "\\text{For}\\ \\ i=1\\ \\ \\text{to}\\ \\ m \\\\\n",
    "\\hspace{15pt}z^{(i)} = w^Tx^{(i)} + b \\\\ \n",
    "\\hspace{15pt}a^{(i)} = \\sigma(z^{(i)}) \\\\\n",
    "\\hspace{15pt}J\\ += - [y^{(i)}\\ log(a^{(i)}) + (1 - y^{(i)})\\ log(1 - a^{(i)})] \\\\\n",
    "\\hspace{15pt}dz^{(i)} = a^{(i)} - y^{(i)} \\\\\n",
    "\\hspace{15pt}dw += x^{(i)}dz^{(i)} \\\\\n",
    "\\hspace{15pt}db += dz^{(i)} \\\\\n",
    "\\hspace{15pt}J\\ /=\\ m \\\\\n",
    "\\hspace{15pt}dw\\ /=\\ m \\\\\n",
    "\\hspace{15pt}db\\ /=\\ m \\\\\n",
    "\\text{Fim for}\n",
    "$\n",
    "\n",
    "### Updating weights\n",
    "\n",
    "$\n",
    "w\\ := w - \\alpha dw \\\\\n",
    "b\\ := b - \\alpha db \\\\\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implementing Vectorization in Forward Propagation \n",
    "\n",
    "$\n",
    "X = \\begin{bmatrix}\n",
    "| & | &  & |\\\\\n",
    "x^{(1)} & x^{(2)} & \\dots & x^{(m)} \\\\\n",
    "| & | &  & |\\\\\n",
    "\\end{bmatrix} \\hspace{15pt}\\rightarrow\\hspace{15pt} (n_x, m)\\hspace{15pt} \\mathbb{R}^{n_x,m}\n",
    "$\n",
    "\n",
    "$\n",
    "Z = [ z^{(1)}\\ \\ z^{(2)}\\ \\ \\dots z^{(m)}] = w^TX + [b, b, \\dots b] \\hspace{15pt}\\rightarrow\\hspace{15pt} b \\in \\mathbb{R} (1,1) matrix \\\\\n",
    "Z = np.dot(w.T, X) + b \\\\\n",
    "A = [ a^{(1)}\\ \\ a^{(2)}\\ \\ \\dots a^{(m)}] = \\sigma(Z)\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Implementing Vectorization in Backward Propagation \n",
    "\n",
    "$\n",
    "dz^{(1)} = a^{(1)} - y^{(1)} \\hspace{15pt} dz^{(2)} = a^{(2)} - y^{(2)} \\dots \\\\\n",
    "dZ = [dz^{(1)}\\ \\ dz^{(2)}\\ \\ \\dots dz^{(m)}] \\\\\n",
    "$\n",
    "\n",
    "Given that:\n",
    "\n",
    "$\n",
    "A = [a^{(1)}\\ \\ a^{(2)}\\ \\ \\dots a^{(m)}]  \\hspace{30pt} Y = [y^{(1)}\\ \\ y^{(2)}\\ \\ \\dots y^{(m)}]\\\\\n",
    "dZ = A - Y \\hspace{15pt}\\rightarrow\\hspace{15pt} [a^{(1)}y^{(1)}\\ \\ a^{(2)}y^{(2)}\\ \\ dots ]\n",
    "db = \\frac{1}{m} np.sum(dZ)\n",
    "dw = \\frac{1}{m} XdZ^T\n",
    "$\n",
    "\n",
    "$\n",
    "dw = \\frac{1}{m} \\begin{bmatrix}\n",
    "| & | &  & |\\\\\n",
    "x^{(1)} & x^{(2)} & \\dots & x^{(m)} \\\\\n",
    "| & | &  & |\\\\\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "dz^{(1)}\\\\\n",
    "dz^{(2)}\\\\\n",
    "\\vdots \\\\\n",
    "dz^{(m)}\\\\\n",
    "\\end{bmatrix}\n",
    "$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
